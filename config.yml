# Model Identifier or path
model_identifier: "Qwen/Qwen2.5-0.5B-Instruct"

# Training parameters
group_size: 16                # Group size used in GRPO
rollouts_per_step: 32         # Number of rollouts before updating model
updates_per_step: 4           # Number of weight updates per step
kl_weight: 0.05               # Weight for KL divergence from reference model
learning_rate: 1e-5           # Learning rate for optimizer
max_completion_len: 640       # Maximum length of generated sequences

# File paths
checkpoint_dir: "checkpoints" # Directory to save model checkpoints
log_dir: "logs"               # Directory for tensorboard logs

# LoRA configuration
use_lora: true                # Whether to use LoRA for parameter-efficient fine-tuning
lora_config:
  r: 16                       # LoRA rank
  alpha: 32                   # LoRA alpha parameter for scaling
  dropout: 0.1               # Dropout probability for LoRA layers
  target_modules:             # Modules to apply LoRA to
    - "q_proj"
    - "k_proj"
    # - "v_proj"
    # - "o_proj"
    - "gate_proj"
    # - "up_proj"
    # - "down_proj"